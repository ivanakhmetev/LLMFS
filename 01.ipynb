{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.1 Что такое ЛЛМ? \n","\n","ЛЛМ - large language model, представляет собой глубокую нейронную сеть, предназначенную для понимания, генерации и реагирования на человеческий текст, обученную  на огромных объемах текстовых данных. \n","\n","Слово large относится:\n"," - к размеру модели с точки зрения параметров (десятки и сотни миллиардов параметров - весовых коэффициентов)\n"," - к набору данных, на котором она обучается (миллиарды токенов - слов или символов) \n"," \n","ЛЛМ относятся к алгоритмам генеративного искусственного интеллекта. Как показано на рисунке, алгоритмы ИИ охватывают широкую область задач, требующих интеллекта, подобного человеческому, включая понимание языка, распознавание шаблонов и принятие решений.\n","\n","![](images/llm1.1.png)\n","\n","Машинное обучение - процесс улучшения решения задач на основе данных. \n","\n","Глубокое обучение — это подмножество машинного обучения, которое фокусируется на использовании нейронных сетей с тремя или более уровнями (также называемых глубокими нейронными сетями) для моделирования сложных шаблонов и абстракций в данных. \n","\n","Представим себе спам-фильтр: вместо того, чтобы вручную писать правила для выявления спам-сообщений, алгоритм машинного обучения получает примеры писем, помеченных как спам и не-спам. На этих данных модель учится распознавать закономерности и характеристики, что позволяет ей классифицировать новые электронные письма. Маркировка спам и не-спам определяется на основе выбранных человеком признаков (частота использования определенных триггерных слов («приз», «выигрыш», «бесплатно»), количество восклицательных знаков, использование всех слов в верхнем регистре или наличие подозрительных ссылок). Модель глубокого обучения выявляет признаки спам-сообщений без участия человека, что позволяет ей выявлять нестандартные признаки исключительно из данных, но создает проблемму интерпретации. \n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.2 Применение ЛЛМ\n","\n","ЛЛМ имеют широкий спектр приложений в различных областях: машинный перевод, создания новых текстов (контента), анализ настроений, обобщения текста, обеспечивать работу чат-ботов и виртуальных помощников, дополнять традиционные поисковые системы. ЛЛМ можно использовать для интеллектуального поиска знаний из огромных объемов текста в специализированных областях, таких как медицина или право. Это включает в себя анализ документов, обобщение длинных отрывков и ответы на технические вопросы.\n","\n","![](images/llm1.2.png)\n","\n","Их применение практически безгранично, и по мере развития прогресса в ИИ, становится ясно, что у ЛЛМ есть потенциал переопределить наши отношения с технологиями (техне - др.греч философский термин относительно делания, технология - знание как делать) в целом."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.3 Этапы создания ЛЛМ\n","\n","Программирование ЛЛМ с нуля — отличное упражнение для понимания её механики и ограничений. Кроме того, это помогает для точной настройки существующих архитектур для пользовательских наборов данных или задач, специфичных для конкретной предметной области.\n","\n","Специально созданные ЛЛМ, предназначенные для конкретных задач или областей, могут превзойти ЛЛМ общего назначения. Примером является BloombergGPT, который специализируется на финансах, модели, предназначенные для ответов на медицинские вопросы.\n","\n","В общем процесс обучения ЛЛМ состоит из предобучения и предметной настройки: сначала модель обучается на большом и разнообразном наборе данных для развития широкого понимания языка. Далее, на базе этой модели происходит второй этап обучения на узком наборе данных, специфичном для предметной области. \n","\n","![](images/llm1.3.png)\n","\n","На первом этапе используется сырой массив текста без дополнительной разметки (исключение - отметки о начале/конце документа, возможна фильтрация специальных символов), получается базовая модель (например GPT-3, предшественница ChatGPT). \n","\n","Далее модель может быть обучена как классификатор или интеллектуальный помощник. В первом случае модель получает размеченный набор данных, состоящий из текстов и связанных с ними меток классов (например электронных писем с меткой спам / не спам). Во втором случае модель получает набор инструкций и реализаций этих инструкций (например запрос на перевод текста и переведенный текст)."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.4 Преобразователь\n","\n","Архитектура преобразователя была предложена в статье 2017 года [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Она состоит из двух частей: шифратора и дешифратора. Модуль шифратора обрабатывает входной текст и кодирует его как числовые вектора. Затем модуль дешифратора из этих векторов генерирует выходной текст. И шифратор, и деширатор состоят из множества слоев, соединенных механизмом самонаблюдения. Этот механизм позволяет модели взвешивать важность разных слов (токенов) в последовательности. Т.е. фиксировать долгосрочные зависимости и контекстуальные связи во входных данных, повышая способность генерировать последовательные и контекстуально релевантные выходные данные. Наиболее известная модель преобразователя - GPT, т.е. generative pretrained transformers, \n","предназначенная для генеративных задач, с точки зрения архитектуры фокусируется на дешифраторе.\n","\n","![](images/llm1.4.png)\n","\n","Также известна модель BERT - bidirectional encoder representations from transformers, которая отражает в названии фокус на дешифраторе.\n","BERT и его варианты специализируются на предсказании скрытых слов. Обнаружение скрытых слов помогает в классификации документов (например обнаружение скрытого токсичного сообщения). \n","\n","![](images/llm1.5.png)\n","\n","Необходимо иметь в виду, что существуют ЛЛМ основанные не на преобразователях, и эта архитектура может работать не в языковой модели. Т.е. ЛЛМ - класс моделей, а преобразователи - класс архитектур. \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.5 Наборы больших данных\n","\n","Большие наборы обучающих данных представляют собой разнообразные и всеобъемлющие текстовые корпуса, охватывающие миллиарды слов и широкий спектр тем, естественных и искусственных языков. Набор данных, использованный для предварительного обучения GPT-3: \n","\n","![](images/llm1.6.png)\n","\n","Важно отметить, что из каждого набора данных в процессе обучения использовалась только часть данных (в общей сложности 300 миллиардов токенов). Это означает, что для обучения использовались не все доступные данные, а их подмножество из 300 миллиардов токенов. Причем некоторые данные не были использованы полностью, а другие могли быть использованы несколько раз.\n","\n","[CommonCrawl](https://commoncrawl.org/) - набор данных, который состоит из 410 миллиардов токенов (570 ГБ).  \n","Wikipedia - англоязычная википедия.  \n","Books1 - скорее всего, является образцом из [Project Gutenberg](https://www.gutenberg.org/).  \n","Books2 - скорее всего, [Libgen](https://en.wikipedia.org/wiki/Library_Genesis).  \n","WebText2 - это текст веб-страниц из ссылок Reddit с 3+ лайками.  \n","Более поздние версии моделей также включают дополнительные источники данных, такие как научные статьи arxiv.org (92 ГБ) и свазанные с кодом вопросы StackExchange (78 ГБ).  \n","\n","Обучение на таком наборе данных требует значительных ресурсов. Стоимость предварительного обучения GPT-3 оценивается в 4,6 миллиона долларов США. \n","Кроме того, производители базовых моделей, цензурируя данные для обучения, получают инструмент влияния на результаты предметных моделей. Это приводит к нравственно-этическому перекосу существующих моделей в пользу предпочтений компаний-разработчиков."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.6 [Архитектура ГПТ](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n","\n","\n","Задачу генерации текста можно рассмотреть как задачу предсказания следующего слова. \"Следующим\" может быть обозначено любое слово во входящем тексте, что позволяет обрабатывать большой обучающий набор без ручной (человеческой) разметки. Поскольку следующее слово зависит от предыдущих, математическая абстракция этой задачи - предсказание временных рядов (авторегрессионная модель).\n","\n","![](images/llm1.7.png)\n","\n","Общая архитектура GPT относительно проста. По сути, это часть дешифратора без шифратора. Однако промышленная модель (96 слоев преобразователя) значительно больше оригинальной модели. В статье рассматривается с шестью блоками дешифратора. В GPT-3 этот блок повторяется 96 раз.\n","\n","![](images/llm1.8.png)\n","\n","GPT-3 был представлен в 2020 году, на сегодняшний (04.2024) день принципальных нововведений в архитектуре нет.\n","\n","Изначально, модель преобразователя была специально разработана для языкового перевода. Но модели GPT - несмотря на более крупную и простую архитектуру (без шифратора), также способны выполнять задачи перевода. Эта возможность изначально была неожиданной для исследователей. Способность выполнять задачи, для выполнения которых модель не была специально обучена, называется \"проявленным свойством\". Эта возможность не обучается явно, но возникает как естественное следствие воздействия огромных объемов данных в различных контекстах. Изучение проявленных свойств - способ получения нового понимания технологии как таковой."]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
